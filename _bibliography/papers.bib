---
---

@inproceedings{wu2023SOCC,
  title={DEA-NIMC: Dynamic Energy-Aware Policy for Near/In-Memory Computing Hybrid Architecture},
  abstract={In-memory computing (IMC) has become the current trend to accelerate the inference of deep neural networks (DNNs). Nonetheless, IMC suffers from variations that significantly degrade the inference accuracy, while near-memory computing (NMC) maintains the ideal accuracy but at the expense of energy efficiency. In this work, we leverage the NMC/IMC hybrid architecture and propose a dynamic energy-aware policy to strike a better trade-off between accuracy and energy efficiency. Our approach takes advantage of deep reinforcement learning (DRL) to dynamically allocate workloads between NMC and IMC at the data level. Furthermore, we consider the varying energy overhead of NMC usage across different DNN layers. Compared with the prior works, we enhance the accuracy by up to 8.8% on CIFAR-10 and 4.6% on CIFAR-100 while consuming the same amount of energy.},
  author={Wu, Yu-Cheng and Huang, Chi-Tse and Wu, An-Yeu Andy},
  booktitle={IEEE International System-on-Chip Conference (SOCC)},
  pages={1--6},
  year={2023},
  organization={IEEE},
  html={https://ieeexplore.ieee.org/abstract/document/10256898?casa_token=qIkk5dIF75kAAAAA:8DpGvlbk0Y7Lcdfg2gXfHUwMBgcjZAEM78ZRoTFczHhM6hTbz1CT03bV9SH94sxZ2czXE4P2zw},
  preview={DEA-NIMC.gif}
}

@inproceedings{wu2024ATVA,
  abbr={ATVA},
  title={Deep-Reinforcement-Learning-Based Design Space Exploration for Time-Sensitive Networking (Accepted)},
  abstract={Time-Sensitive Networking (TSN) has become a favorable option for real-time communication in Cyber-Physical Systems (CPSs), such as intelligent vehicles and industrial control systems, due to its capability of providing bounded end-to-end latencies. However, designing CPSs on a TSN network can be an NP-hard combinatorial optimization problem. Therefore, a formal and efficient approach is desired to explore the design space with different combinations of data flow periods. Accordingly, we propose a novel design flow that preemptively generates a set of schedulable period lists, guaranteeing that all data flow deadlines can be met. We further employ Deep Reinforcement Learning (DRL) to optimize the collecting process of these period lists. The experimental result demonstrates remarkable success where 97.02% of solutions are found with 4.85X speed higher than the method based on Satisfiability Modulo Theories. The result of large-scale scenarios also reveals that our approach outperforms any other comparative method by at least 3.93X more schedulable period lists collected.},
  author={Wu, Yu-Cheng and Tseng, I-Ching and Lin, Chung-Wei},
  booktitle={International Symposium on Automated Technology for Verification and Analysis},
  year={2024},
  organization={Springer}
}